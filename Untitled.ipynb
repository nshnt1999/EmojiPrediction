{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unusual-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "military-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./dataset/dataset/train_emoji.csv',header=None)\n",
    "test = pd.read_csv('./dataset/dataset/test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latest-vacation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lined-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "                    \"0\": \"\\u2764\\uFE0F\",    \n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
    "                    \"3\": \":downcast_face_with_sweat:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "closing-comparative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÅ\n",
      "üòì\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for i in emoji_dictionary.values():\n",
    "    print(emoji.emojize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acquired-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòì\n",
      "I am proud of your achievements üòÅ\n",
      "It is the worst day in my life üòì\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòì\n",
      "congratulations on your acceptance üòÅ\n",
      "The assignment is too long  üòì\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(train.iloc[i,0],emoji.emojize(emoji_dictionary[str(train.iloc[i,1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lucky-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "referenced-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132, 5)\n",
      "(56,)\n",
      "(56, 5)\n"
     ]
    }
   ],
   "source": [
    "XT = train[0]\n",
    "Xt = test[0]\n",
    "\n",
    "YT = to_categorical(train[1])\n",
    "Yt = to_categorical(test[1])\n",
    "\n",
    "print(XT.shape)\n",
    "print(YT.shape)\n",
    "print(Xt.shape)\n",
    "print(Yt.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "social-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings={}\n",
    "with open('glove.6B.50d.txt',encoding='UTF-8') as f:\n",
    "    for lines in f:\n",
    "        values = lines.split()\n",
    "        embeddings[values[0]]=np.array(values[1:],dtype='float64')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "promotional-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix(X):\n",
    "    embedding_matrix = np.zeros((X.shape[0],10,50))       ##the size of embeddings will be (X.shape[0],10,50)\n",
    "    for ix in range(X.shape[0]):\n",
    "        words = X[ix].split()\n",
    "        for jx in range(len(words)):\n",
    "            embedding_matrix[ix,jx]=embeddings[words[jx].lower()]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "organic-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_XT = getEmbeddingMatrix(XT)\n",
    "emb_Xt = getEmbeddingMatrix(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "joined-laundry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(emb_XT.shape)\n",
    "print(emb_Xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rolled-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "inner-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sized-yukon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(LSTM(64,input_shape=(10,50)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "through-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 4s 297ms/step - loss: 1.5883 - accuracy: 0.3101 - val_loss: 1.5963 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59629, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.5418 - accuracy: 0.3377 - val_loss: 1.5957 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59629 to 1.59574, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.5221 - accuracy: 0.3556 - val_loss: 1.5937 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.59574 to 1.59367, saving model to best_model.h5\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.4802 - accuracy: 0.4018 - val_loss: 1.5807 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.59367 to 1.58068, saving model to best_model.h5\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.4783 - accuracy: 0.3848 - val_loss: 1.5566 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.58068 to 1.55663, saving model to best_model.h5\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.4463 - accuracy: 0.4388 - val_loss: 1.5235 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.55663 to 1.52347, saving model to best_model.h5\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.3875 - accuracy: 0.4750 - val_loss: 1.4741 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.52347 to 1.47408, saving model to best_model.h5\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3333 - accuracy: 0.5813 - val_loss: 1.4239 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.47408 to 1.42394, saving model to best_model.h5\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.2410 - accuracy: 0.6107 - val_loss: 1.3796 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.42394 to 1.37960, saving model to best_model.h5\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2148 - accuracy: 0.5865 - val_loss: 1.3196 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.37960 to 1.31956, saving model to best_model.h5\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1308 - accuracy: 0.6386 - val_loss: 1.2716 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.31956 to 1.27158, saving model to best_model.h5\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0500 - accuracy: 0.6370 - val_loss: 1.2016 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.27158 to 1.20161, saving model to best_model.h5\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9901 - accuracy: 0.7006 - val_loss: 1.1784 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.20161 to 1.17838, saving model to best_model.h5\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.8309 - accuracy: 0.7295 - val_loss: 1.3064 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.17838\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7935 - accuracy: 0.7225 - val_loss: 1.0957 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.17838 to 1.09568, saving model to best_model.h5\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7091 - accuracy: 0.7835 - val_loss: 1.0959 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.09568\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6512 - accuracy: 0.7540 - val_loss: 0.9522 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.09568 to 0.95221, saving model to best_model.h5\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5323 - accuracy: 0.8319 - val_loss: 1.1063 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.95221\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5817 - accuracy: 0.7921 - val_loss: 1.1410 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.95221\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6132 - accuracy: 0.7983 - val_loss: 0.7527 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.95221 to 0.75267, saving model to best_model.h5\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.5532 - accuracy: 0.8416 - val_loss: 1.3838 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.75267\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4781 - accuracy: 0.8567 - val_loss: 1.0864 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.75267\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4054 - accuracy: 0.8312 - val_loss: 0.8735 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.75267\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3459 - accuracy: 0.8913 - val_loss: 1.1982 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.75267\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3764 - accuracy: 0.8768 - val_loss: 1.0869 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.75267\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3064 - accuracy: 0.8835 - val_loss: 0.9990 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.75267\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3152 - accuracy: 0.9257 - val_loss: 1.3396 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.75267\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2958 - accuracy: 0.9088 - val_loss: 1.1797 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.75267\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2641 - accuracy: 0.9062 - val_loss: 1.2384 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.75267\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2596 - accuracy: 0.9270 - val_loss: 1.0675 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.75267\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1667 - accuracy: 0.9846 - val_loss: 1.1679 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.75267\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1487 - accuracy: 0.9677 - val_loss: 1.1466 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.75267\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1388 - accuracy: 0.9825 - val_loss: 1.2815 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.75267\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1340 - accuracy: 0.9784 - val_loss: 1.0454 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.75267\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1301 - accuracy: 0.9766 - val_loss: 1.4660 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.75267\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1367 - accuracy: 0.9680 - val_loss: 0.7967 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.75267\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1735 - accuracy: 0.9570 - val_loss: 1.3441 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.75267\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1108 - accuracy: 0.9570 - val_loss: 1.1333 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.75267\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1161 - accuracy: 0.9857 - val_loss: 1.0819 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.75267\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1108 - accuracy: 0.9966 - val_loss: 1.6730 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_loss did not improve from 0.75267\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1875 - accuracy: 0.9732 - val_loss: 0.9324 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.75267\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1285 - accuracy: 0.9508 - val_loss: 1.0297 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.75267\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0858 - accuracy: 0.9805 - val_loss: 1.4177 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.75267\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.75267\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.75267\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0525 - accuracy: 0.9914 - val_loss: 1.1066 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.75267\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 1.1821 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.75267\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.2090 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.75267\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.1999 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.75267\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 1.1909 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.75267\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.1943 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.75267\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0516 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.75267\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.75267\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.1646 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.75267\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.2968 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.75267\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.3570 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.75267\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.2381 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.75267\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.1675 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.75267\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.3011 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.75267\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.3923 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.75267\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3135 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.75267\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.2439 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.75267\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.2549 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.75267\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.3117 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.75267\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.3908 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.75267\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.3144 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.75267\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.2279 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.75267\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.2640 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.75267\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.3623 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.75267\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.4347 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.75267\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.4378 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.75267\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.3667 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.75267\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.75267\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3887 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.75267\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.3843 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.75267\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.75267\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.3817 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.75267\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5127 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.75267\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.5149 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.75267\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4360 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.75267\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.75267\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.3841 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.75267\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4244 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.75267\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4861 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.75267\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.6085 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.75267\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.6875 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.75267\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.6727 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.75267\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.4389 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.75267\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2993 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.75267\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4763 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.75267\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.5774 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.75267\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5624 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.75267\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5511 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.75267\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.4919 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.75267\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.4657 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.75267\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.4601 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.75267\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4924 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.75267\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5456 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.75267\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.5950 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.75267\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6338 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.75267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ecd2f84e48>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('best_model.h5',monitoer='val_loss',verbose=True,save_best_only=True)\n",
    "#earlystop = EarlyStopping(monitor='val_loss',patience=20)\n",
    "model.fit(emb_XT,YT,batch_size=32,epochs=100,shuffle=True,validation_split=0.1,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "forward-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "friendly-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 1.1330 - accuracy: 0.5893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1330463886260986, 0.5892857313156128]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(emb_Xt,Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "previous-banking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anilkumar\\.conda\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(emb_Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "inner-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\t\n",
      "üç¥\n",
      "üç¥\n",
      "he did not answer\t\n",
      "üòì\n",
      "üòì\n",
      "he got a raise\t\n",
      "üòÅ\n",
      "üòì\n",
      "she got me a present\t\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "ha ha ha it was so funny\t\n",
      "üòÅ\n",
      "üòÅ\n",
      "he is a good friend\t\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n",
      "I am upset\t\n",
      "‚ù§Ô∏è\n",
      "üòì\n",
      "We had such a lovely dinner tonight\t\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n",
      "where is the food\t\n",
      "üç¥\n",
      "üç¥\n",
      "Stop making this joke ha ha ha\t\n",
      "üòÅ\n",
      "üòÅ\n",
      "where is the ball\t\n",
      "‚öæ\n",
      "‚öæ\n",
      "work is hard\t\n",
      "üòì\n",
      "üòÅ\n",
      "This girl is messing with me\t\n",
      "üòì\n",
      "üòì\n",
      "are you serious ha ha\t\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "Let us go play baseball\t\n",
      "‚öæ\n",
      "‚öæ\n",
      "This stupid grader is not working \t\n",
      "üòì\n",
      "üòì\n",
      "work is horrible\t\n",
      "üòì\n",
      "üòì\n",
      "Congratulation for having a baby\t\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "stop messing around\t\n",
      "üòì\n",
      "üòì\n",
      "any suggestions for dinner\t\n",
      "üç¥\n",
      "üç¥\n",
      "I love taking breaks\t\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "you brighten my day\t\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "I boiled rice\t\n",
      "üç¥\n",
      "üç¥\n",
      "she is a bully\t\n",
      "üòì\n",
      "‚ù§Ô∏è\n",
      "Why are you feeling bad\t\n",
      "üòì\n",
      "üòì\n",
      "I am upset\t\n",
      "üòì\n",
      "üòì\n",
      "I worked during my birthday\t\n",
      "üòì\n",
      "‚ù§Ô∏è\n",
      "My grandmother is the love of my life\t\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "enjoy your break\t\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "valentine day is near\t\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n",
      "I miss you so much\t\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "throw the ball\t\n",
      "‚öæ\n",
      "‚öæ\n",
      "My life is so boring\t\n",
      "üòì\n",
      "‚ù§Ô∏è\n",
      "she said yes\t\n",
      "üòÅ\n",
      "üòì\n",
      "will you be my valentine\t\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "he can pitch really well\t\n",
      "‚öæ\n",
      "‚öæ\n",
      "dance with me\t\n",
      "üòÅ\n",
      "üòÅ\n",
      "I am starving\t\n",
      "üç¥\n",
      "‚ù§Ô∏è\n",
      "See you at the restaurant\t\n",
      "üç¥\n",
      "üç¥\n",
      "I like to laugh\t\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "I will go dance\n",
      "üòÅ\n",
      "‚öæ\n",
      "I like your jacket \t\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "i miss her\t\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "what is your favorite baseball game\t\n",
      "‚öæ\n",
      "‚öæ\n",
      "Good job\t\n",
      "üòÅ\n",
      "üòÅ\n",
      "I love to the stars and back\t\n",
      "‚ù§Ô∏è\n",
      "üòì\n",
      "What you did was awesome\t\n",
      "üòÅ\n",
      "üòì\n",
      "ha ha ha lol\t\n",
      "üòÅ\n",
      "üòÅ\n",
      "I want to joke\t\n",
      "üòÅ\n",
      "üòì\n",
      "go away\t\n",
      "üòì\n",
      "üòì\n",
      "yesterday we lost again\t\n",
      "üòì\n",
      "üòì\n",
      "family is all I have\t\n",
      "‚ù§Ô∏è\n",
      "üòì\n",
      "you are failing this exercise\t\n",
      "üòì\n",
      "üòì\n",
      "Good joke\t\n",
      "üòÅ\n",
      "üòÅ\n",
      "You totally deserve this prize\t\n",
      "üòÅ\n",
      "üòì\n",
      "I did not have breakfast \n",
      "üòì\n",
      "üòì\n"
     ]
    }
   ],
   "source": [
    "for i in range(Xt.shape[0]):\n",
    "    print(Xt[i])\n",
    "    print(emoji.emojize(emoji_dictionary[str(np.argmax(Yt[i]))]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "certain-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###Applying stacked LSTM\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(LSTM(64,input_shape=(10,50)))\n",
    "model1.add(Dropout(0.4))\n",
    "model1.add(Dense(5,activation='softmax'))\n",
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model1.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "laden-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "educational-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 7s 545ms/step - loss: 1.5927 - accuracy: 0.2845 - val_loss: 1.5913 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59133, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5430 - accuracy: 0.3580 - val_loss: 1.5708 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59133 to 1.57084, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.5273 - accuracy: 0.3390 - val_loss: 1.5578 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.57084 to 1.55776, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.4347 - accuracy: 0.3838 - val_loss: 1.5646 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.55776\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4033 - accuracy: 0.4010 - val_loss: 1.5399 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.55776 to 1.53988, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.3321 - accuracy: 0.4364 - val_loss: 1.4495 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.53988 to 1.44955, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.2490 - accuracy: 0.5117 - val_loss: 1.3569 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.44955 to 1.35685, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1611 - accuracy: 0.5914 - val_loss: 1.3160 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.35685 to 1.31600, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.1496 - accuracy: 0.5274 - val_loss: 1.2703 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.31600 to 1.27028, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0286 - accuracy: 0.6264 - val_loss: 1.2634 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.27028 to 1.26339, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9242 - accuracy: 0.6756 - val_loss: 1.2434 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.26339 to 1.24339, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8776 - accuracy: 0.6787 - val_loss: 1.0307 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.24339 to 1.03067, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7728 - accuracy: 0.7311 - val_loss: 1.1532 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.03067\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.6424 - accuracy: 0.7903 - val_loss: 1.2750 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.03067\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7011 - accuracy: 0.7981 - val_loss: 0.9647 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.03067 to 0.96475, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.6264 - accuracy: 0.7694 - val_loss: 1.0397 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.96475\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4935 - accuracy: 0.8306 - val_loss: 1.1435 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.96475\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5315 - accuracy: 0.8038 - val_loss: 0.9676 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.96475\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4266 - accuracy: 0.8572 - val_loss: 1.0915 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.96475\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3634 - accuracy: 0.8705 - val_loss: 1.2338 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.96475\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4117 - accuracy: 0.8799 - val_loss: 0.7243 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.96475 to 0.72433, saving model to best_model_stackedLSTM.h5\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4001 - accuracy: 0.8794 - val_loss: 1.0093 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.72433\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3249 - accuracy: 0.8838 - val_loss: 1.1716 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.72433\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2562 - accuracy: 0.9158 - val_loss: 0.9491 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.72433\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3172 - accuracy: 0.8971 - val_loss: 0.9477 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.72433\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2108 - accuracy: 0.9390 - val_loss: 1.0186 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.72433\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2322 - accuracy: 0.9377 - val_loss: 0.9082 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.72433\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2064 - accuracy: 0.9450 - val_loss: 1.0970 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.72433\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1832 - accuracy: 0.9403 - val_loss: 1.1059 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.72433\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1600 - accuracy: 0.9453 - val_loss: 1.4517 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.72433\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1626 - accuracy: 0.9471 - val_loss: 1.1340 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.72433\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1700 - accuracy: 0.9708 - val_loss: 1.1360 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.72433\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1087 - accuracy: 0.9742 - val_loss: 1.1774 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.72433\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1172 - accuracy: 0.9825 - val_loss: 1.3992 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.72433\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1476 - accuracy: 0.9656 - val_loss: 1.1293 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.72433\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1223 - accuracy: 0.9773 - val_loss: 1.4722 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.72433\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1074 - accuracy: 0.9739 - val_loss: 1.2338 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.72433\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0670 - accuracy: 0.9911 - val_loss: 1.2996 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.72433\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0521 - accuracy: 0.9914 - val_loss: 1.5805 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.72433\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0781 - accuracy: 0.9891 - val_loss: 1.3194 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.72433\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0692 - accuracy: 0.9771 - val_loss: 1.2149 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.72433\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0566 - accuracy: 0.9914 - val_loss: 1.4305 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.72433\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1292 - accuracy: 0.9549 - val_loss: 1.4832 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.72433\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0935 - accuracy: 0.9739 - val_loss: 1.2572 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.72433\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2109 - accuracy: 0.9221 - val_loss: 0.7399 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.72433\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1827 - accuracy: 0.9333 - val_loss: 1.5363 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.72433\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2008 - accuracy: 0.9247 - val_loss: 1.1923 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.72433\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0798 - accuracy: 0.9846 - val_loss: 0.9682 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.72433\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1188 - accuracy: 0.9508 - val_loss: 1.0870 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.72433\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0614 - accuracy: 0.9880 - val_loss: 1.1649 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.72433\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 1.2632 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.72433\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0811 - accuracy: 0.9859 - val_loss: 1.1644 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.72433\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0361 - accuracy: 0.9945 - val_loss: 1.0749 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.72433\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.72433\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0381 - accuracy: 0.9852 - val_loss: 1.0280 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.72433\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.72433\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.0829 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.72433\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.1540 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.72433\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0254 - accuracy: 0.9966 - val_loss: 1.1318 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.72433\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.72433\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.72433\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.1362 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.72433\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.72433\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2567 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.72433\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.3330 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.72433\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.3517 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.72433\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.72433\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.72433\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.5401 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.72433\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.5846 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.72433\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.72433\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3525 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.72433\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.7286 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.72433\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.9817 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.72433\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.8005 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.72433\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3538 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.72433\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.1614 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.72433\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.3593 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.72433\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5890 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.72433\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.72433\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.3335 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.72433\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0370 - accuracy: 0.9891 - val_loss: 1.8003 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00082: val_loss did not improve from 0.72433\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 1.6991 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.72433\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0195 - accuracy: 0.9966 - val_loss: 1.3587 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.72433\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0280 - accuracy: 0.9945 - val_loss: 2.6738 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.72433\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0513 - accuracy: 0.9703 - val_loss: 1.6378 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.72433\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.2791 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.72433\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0200 - accuracy: 0.9914 - val_loss: 1.3437 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.72433\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 1.3146 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.72433\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.72433\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0369 - accuracy: 0.9852 - val_loss: 1.0897 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.72433\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.2405 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.72433\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.72433\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1933 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.72433\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1476 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.72433\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1538 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.72433\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.0778 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.72433\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9028 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.72433\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9202 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.72433\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.72433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ecd07ba668>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "checkpoint1 = ModelCheckpoint('best_model_stackedLSTM.h5',monitoer='val_loss',verbose=True,save_best_only=True)\n",
    "#earlystop = EarlyStopping(monitor='val_loss',patience=20)\n",
    "model1.fit(emb_XT,YT,batch_size=32,epochs=100,shuffle=True,validation_split=0.1,callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bizarre-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_weights('best_model_stackedLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "young-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0137 - accuracy: 0.6607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0137073993682861, 0.6607142686843872]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(emb_Xt,Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-buyer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-staff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
